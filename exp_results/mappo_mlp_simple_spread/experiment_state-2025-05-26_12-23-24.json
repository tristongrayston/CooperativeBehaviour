{
  "checkpoints": [
    "{\n  \"trainable_name\": \"MAPPOTrainer\",\n  \"trial_id\": \"e44ca_00000\",\n  \"config\": {\n    \"batch_mode\": \"truncate_episodes\",\n    \"train_batch_size\": 50,\n    \"sgd_minibatch_size\": 50,\n    \"lr\": 0.0005,\n    \"entropy_coeff\": 0.01,\n    \"num_sgd_iter\": 2,\n    \"clip_param\": 0.3,\n    \"use_gae\": true,\n    \"lambda\": 1.0,\n    \"vf_loss_coeff\": 1.0,\n    \"kl_coeff\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"model\": {\n      \"custom_model\": \"Centralized_Critic_Model\",\n      \"custom_model_config\": {\n        \"env\": \"mpe\",\n        \"env_args\": {\n          \"continuous_actions\": false,\n          \"max_cycles\": 25,\n          \"map_name\": \"simple_spread\"\n        },\n        \"mask_flag\": false,\n        \"global_state_flag\": false,\n        \"opp_action_in_cc\": true,\n        \"agent_level_batch_update\": false,\n        \"force_coop\": true,\n        \"local_mode\": true,\n        \"share_policy\": \"group\",\n        \"evaluation_interval\": 50,\n        \"framework\": \"torch\",\n        \"num_workers\": 1,\n        \"num_gpus\": 1,\n        \"num_cpus_per_worker\": 1,\n        \"num_gpus_per_worker\": 0,\n        \"checkpoint_freq\": 100,\n        \"checkpoint_end\": true,\n        \"restore_path\": {\n          \"model_path\": \"\",\n          \"params_path\": \"\"\n        },\n        \"stop_iters\": 9999999,\n        \"stop_timesteps\": 2000000,\n        \"stop_reward\": 999999,\n        \"seed\": 321,\n        \"local_dir\": \"\",\n        \"model_arch_args\": {\n          \"hidden_state_size\": 256,\n          \"core_arch\": \"mlp\",\n          \"fc_layer\": 2,\n          \"out_dim_fc_0\": 128,\n          \"out_dim_fc_1\": 64,\n          \"encode_layer\": \"8-16\"\n        },\n        \"algorithm\": \"mappo\",\n        \"space_obs\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595aa020000000000008c0f67796d2e7370616365732e64696374948c04446963749493942981947d94288c06737061636573948c0b636f6c6c656374696f6e73948c0b4f726465726564446963749493942952948c036f6273948c0e67796d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994681093948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c065f7368617065944b1285948c036c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289648000000000000000000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c29468128c02663494898887945294284b0368164e4e4e4affffffff4affffffff4b007494624b1285948c014394749452948c046869676894681d289648000000000000000000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8429468214b1285946824749452948c086c6f775f72657072948c062d3130302e30948c09686967685f72657072948c053130302e30948c0d626f756e6465645f62656c6f7794681d289612000000000000000101010101010101010101010101010101019468128c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b1285946824749452948c0d626f756e6465645f61626f766594681d289612000000000000000101010101010101010101010101010101019468344b1285946824749452948c0a5f6e705f72616e646f6d944e75627368184e68104e683f4e75622e\"\n        },\n        \"space_act\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005958c000000000000008c1367796d2e7370616365732e6469736372657465948c0844697363726574659493942981947d94288c016e944b058c057374617274944b008c065f736861706594298c056474797065948c056e756d707994680893948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        \"num_agents\": 3,\n        \"episode_limit\": 25,\n        \"policy_mapping_info\": {\n          \"simple_adversary\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_crypto\": {\n            \"description\": \"two team cooperate, one team attack\",\n            \"team_prefix\": [\n              \"eve_\",\n              \"bob_\",\n              \"alice_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_push\": {\n            \"description\": \"one team target on landmark, one team attack\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_tag\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_spread\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_reference\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_world_comm\": {\n            \"description\": \"two team cooperate and attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"leadadversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_speaker_listener\": {\n            \"description\": \"two team cooperate\",\n            \"team_prefix\": [\n              \"speaker_\",\n              \"listener_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          }\n        },\n        \"agent_name_ls\": [\n          \"agent_0\",\n          \"agent_1\",\n          \"agent_2\"\n        ]\n      }\n    },\n    \"seed\": 321,\n    \"env\": \"mpe_simple_spread\",\n    \"num_gpus_per_worker\": 0,\n    \"num_gpus\": 1,\n    \"num_workers\": 1,\n    \"multiagent\": {\n      \"policies\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059515000000000000008f94288c0d7368617265645f706f6c69637994902e\"\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c9020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b024b004b004b034b014b1b430488005300944e8594298c086167656e745f6964948c07657069736f6465948c066b77617267739487948c6b2f6d6e742f632f55736572732f67726179732f4f6e6544726976652f4465736b746f702f676974687562207468696e67732f436f6f70657261746976654265686176696f75722f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e7079948c083c6c616d6264613e944b7a4300948c127368617265645f706f6c6963795f6e616d6594859429749452947d94288c0b5f5f7061636b6167655f5f948c126d61726c6c69622e6d61726c2e616c676f73948c085f5f6e616d655f5f948c196d61726c6c69622e6d61726c2e616c676f732e72756e5f6363948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c9493942952948594749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1872756e5f63632e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493948c0d7368617265645f706f6c696379948594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      }\n    },\n    \"framework\": \"torch\",\n    \"evaluation_interval\": 50,\n    \"simple_optimizer\": false\n  },\n  \"local_dir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread\",\n  \"evaluated_params\": {\n    \"lr\": 0.0005,\n    \"model/custom_model_config/model_arch_args/encode_layer\": \"8-16\"\n  },\n  \"experiment_tag\": \"0_lr=0.0005,encode_layer=8-16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b8000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d94286808473ff0000000000000680947000000000000000075658c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"episode_reward_mean\": 999999,\n    \"timesteps_total\": 1000000,\n    \"training_iteration\": 9999999\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1748287405.139619,\n  \"logdir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00000_0_lr=0.0005,encode_layer=8-16_2025-05-26_12-23-24\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00000_0_lr=0.0005,encode_layer=8-16_2025-05-26_12-23-24/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trial_runner.py\\\", line 890, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\\\", line 788, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/worker.py\\\", line 1625, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::MAPPOTrainer.train()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=MAPPOTrainer)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 679, in train\\n    raise e\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 668, in train\\n    result = Trainable.train(self)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trainable.py\\\", line 283, in train\\n    result = self.step()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\\\", line 206, in step\\n    step_results = next(self.train_exec_impl)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 756, in __next__\\n    return next(self.built_iterator)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 876, in apply_flatten\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 471, in base_iterator\\n    yield ray.get(futures, timeout=timeout)\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::RolloutWorker.par_iter_next()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=<ray.rllib.evaluation.rollout_worker.modify_class.<locals>.Class object at 0x7f7efdc55eb0>)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 1151, in par_iter_next\\n    return next(self.local_it)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 378, in gen_rollouts\\n    yield self.sample()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 753, in sample\\n    batches = [self.input_reader.next()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 103, in next\\n    batches = [self.get_data()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 233, in get_data\\n    item = next(self._env_runner)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 591, in _env_runner\\n    summarize(unfiltered_obs)))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 20, in summarize\\n    return _printer.pformat(_summarize(obj))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in _summarize\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in <dictcomp>\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in _summarize\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in <dictcomp>\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in _summarize\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in <dictcomp>\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 39, in _summarize\\n    elif obj.dtype == np.object or obj.dtype.type is np.str_:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/numpy/__init__.py\\\", line 305, in __getattr__\\n    raise AttributeError(__former_attrs__[attr])\\nAttributeError: module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_to_cloud\": null,\n  \"checkpoint_freq\": 100,\n  \"checkpoint_at_end\": true,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MAPPOTrainer\",\n  \"trial_id\": \"e44ca_00001\",\n  \"config\": {\n    \"batch_mode\": \"truncate_episodes\",\n    \"train_batch_size\": 50,\n    \"sgd_minibatch_size\": 50,\n    \"lr\": 0.001,\n    \"entropy_coeff\": 0.01,\n    \"num_sgd_iter\": 2,\n    \"clip_param\": 0.3,\n    \"use_gae\": true,\n    \"lambda\": 1.0,\n    \"vf_loss_coeff\": 1.0,\n    \"kl_coeff\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"model\": {\n      \"custom_model\": \"Centralized_Critic_Model\",\n      \"custom_model_config\": {\n        \"env\": \"mpe\",\n        \"env_args\": {\n          \"continuous_actions\": false,\n          \"max_cycles\": 25,\n          \"map_name\": \"simple_spread\"\n        },\n        \"mask_flag\": false,\n        \"global_state_flag\": false,\n        \"opp_action_in_cc\": true,\n        \"agent_level_batch_update\": false,\n        \"force_coop\": true,\n        \"local_mode\": true,\n        \"share_policy\": \"group\",\n        \"evaluation_interval\": 50,\n        \"framework\": \"torch\",\n        \"num_workers\": 1,\n        \"num_gpus\": 1,\n        \"num_cpus_per_worker\": 1,\n        \"num_gpus_per_worker\": 0,\n        \"checkpoint_freq\": 100,\n        \"checkpoint_end\": true,\n        \"restore_path\": {\n          \"model_path\": \"\",\n          \"params_path\": \"\"\n        },\n        \"stop_iters\": 9999999,\n        \"stop_timesteps\": 2000000,\n        \"stop_reward\": 999999,\n        \"seed\": 321,\n        \"local_dir\": \"\",\n        \"model_arch_args\": {\n          \"hidden_state_size\": 256,\n          \"core_arch\": \"mlp\",\n          \"fc_layer\": 2,\n          \"out_dim_fc_0\": 128,\n          \"out_dim_fc_1\": 64,\n          \"encode_layer\": \"8-16\"\n        },\n        \"algorithm\": \"mappo\",\n        \"space_obs\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595aa020000000000008c0f67796d2e7370616365732e64696374948c04446963749493942981947d94288c06737061636573948c0b636f6c6c656374696f6e73948c0b4f726465726564446963749493942952948c036f6273948c0e67796d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994681093948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c065f7368617065944b1285948c036c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289648000000000000000000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c29468128c02663494898887945294284b0368164e4e4e4affffffff4affffffff4b007494624b1285948c014394749452948c046869676894681d289648000000000000000000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8429468214b1285946824749452948c086c6f775f72657072948c062d3130302e30948c09686967685f72657072948c053130302e30948c0d626f756e6465645f62656c6f7794681d289612000000000000000101010101010101010101010101010101019468128c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b1285946824749452948c0d626f756e6465645f61626f766594681d289612000000000000000101010101010101010101010101010101019468344b1285946824749452948c0a5f6e705f72616e646f6d944e75627368184e68104e683f4e75622e\"\n        },\n        \"space_act\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005958c000000000000008c1367796d2e7370616365732e6469736372657465948c0844697363726574659493942981947d94288c016e944b058c057374617274944b008c065f736861706594298c056474797065948c056e756d707994680893948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        \"num_agents\": 3,\n        \"episode_limit\": 25,\n        \"policy_mapping_info\": {\n          \"simple_adversary\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_crypto\": {\n            \"description\": \"two team cooperate, one team attack\",\n            \"team_prefix\": [\n              \"eve_\",\n              \"bob_\",\n              \"alice_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_push\": {\n            \"description\": \"one team target on landmark, one team attack\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_tag\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_spread\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_reference\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_world_comm\": {\n            \"description\": \"two team cooperate and attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"leadadversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_speaker_listener\": {\n            \"description\": \"two team cooperate\",\n            \"team_prefix\": [\n              \"speaker_\",\n              \"listener_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          }\n        },\n        \"agent_name_ls\": [\n          \"agent_0\",\n          \"agent_1\",\n          \"agent_2\"\n        ]\n      }\n    },\n    \"seed\": 321,\n    \"env\": \"mpe_simple_spread\",\n    \"num_gpus_per_worker\": 0,\n    \"num_gpus\": 1,\n    \"num_workers\": 1,\n    \"multiagent\": {\n      \"policies\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059515000000000000008f94288c0d7368617265645f706f6c69637994902e\"\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c9020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b024b004b004b034b014b1b430488005300944e8594298c086167656e745f6964948c07657069736f6465948c066b77617267739487948c6b2f6d6e742f632f55736572732f67726179732f4f6e6544726976652f4465736b746f702f676974687562207468696e67732f436f6f70657261746976654265686176696f75722f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e7079948c083c6c616d6264613e944b7a4300948c127368617265645f706f6c6963795f6e616d6594859429749452947d94288c0b5f5f7061636b6167655f5f948c126d61726c6c69622e6d61726c2e616c676f73948c085f5f6e616d655f5f948c196d61726c6c69622e6d61726c2e616c676f732e72756e5f6363948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c9493942952948594749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1872756e5f63632e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493948c0d7368617265645f706f6c696379948594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      }\n    },\n    \"framework\": \"torch\",\n    \"evaluation_interval\": 50,\n    \"simple_optimizer\": false\n  },\n  \"local_dir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread\",\n  \"evaluated_params\": {\n    \"lr\": 0.001,\n    \"model/custom_model_config/model_arch_args/encode_layer\": \"8-16\"\n  },\n  \"experiment_tag\": \"1_lr=0.001,encode_layer=8-16\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b8000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d94286808473ff0000000000000680947000000000000000075658c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"episode_reward_mean\": 999999,\n    \"timesteps_total\": 1000000,\n    \"training_iteration\": 9999999\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1748287405.9452791,\n  \"logdir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00001_1_lr=0.001,encode_layer=8-16_2025-05-26_12-23-25\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00001_1_lr=0.001,encode_layer=8-16_2025-05-26_12-23-25/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trial_runner.py\\\", line 890, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\\\", line 788, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/worker.py\\\", line 1625, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::MAPPOTrainer.train()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=MAPPOTrainer)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 679, in train\\n    raise e\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 668, in train\\n    result = Trainable.train(self)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trainable.py\\\", line 283, in train\\n    result = self.step()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\\\", line 206, in step\\n    step_results = next(self.train_exec_impl)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 756, in __next__\\n    return next(self.built_iterator)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 876, in apply_flatten\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 471, in base_iterator\\n    yield ray.get(futures, timeout=timeout)\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::RolloutWorker.par_iter_next()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=<ray.rllib.evaluation.rollout_worker.modify_class.<locals>.Class object at 0x7f7efdc55e50>)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 1151, in par_iter_next\\n    return next(self.local_it)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 378, in gen_rollouts\\n    yield self.sample()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 753, in sample\\n    batches = [self.input_reader.next()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 103, in next\\n    batches = [self.get_data()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 233, in get_data\\n    item = next(self._env_runner)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 599, in _env_runner\\n    _process_observations(\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 818, in _process_observations\\n    summarize(prep_obs)))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 20, in summarize\\n    return _printer.pformat(_summarize(obj))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 39, in _summarize\\n    elif obj.dtype == np.object or obj.dtype.type is np.str_:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/numpy/__init__.py\\\", line 305, in __getattr__\\n    raise AttributeError(__former_attrs__[attr])\\nAttributeError: module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_to_cloud\": null,\n  \"checkpoint_freq\": 100,\n  \"checkpoint_at_end\": true,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MAPPOTrainer\",\n  \"trial_id\": \"e44ca_00003\",\n  \"config\": {\n    \"batch_mode\": \"truncate_episodes\",\n    \"train_batch_size\": 50,\n    \"sgd_minibatch_size\": 50,\n    \"lr\": 0.001,\n    \"entropy_coeff\": 0.01,\n    \"num_sgd_iter\": 2,\n    \"clip_param\": 0.3,\n    \"use_gae\": true,\n    \"lambda\": 1.0,\n    \"vf_loss_coeff\": 1.0,\n    \"kl_coeff\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"model\": {\n      \"custom_model\": \"Centralized_Critic_Model\",\n      \"custom_model_config\": {\n        \"env\": \"mpe\",\n        \"env_args\": {\n          \"continuous_actions\": false,\n          \"max_cycles\": 25,\n          \"map_name\": \"simple_spread\"\n        },\n        \"mask_flag\": false,\n        \"global_state_flag\": false,\n        \"opp_action_in_cc\": true,\n        \"agent_level_batch_update\": false,\n        \"force_coop\": true,\n        \"local_mode\": true,\n        \"share_policy\": \"group\",\n        \"evaluation_interval\": 50,\n        \"framework\": \"torch\",\n        \"num_workers\": 1,\n        \"num_gpus\": 1,\n        \"num_cpus_per_worker\": 1,\n        \"num_gpus_per_worker\": 0,\n        \"checkpoint_freq\": 100,\n        \"checkpoint_end\": true,\n        \"restore_path\": {\n          \"model_path\": \"\",\n          \"params_path\": \"\"\n        },\n        \"stop_iters\": 9999999,\n        \"stop_timesteps\": 2000000,\n        \"stop_reward\": 999999,\n        \"seed\": 321,\n        \"local_dir\": \"\",\n        \"model_arch_args\": {\n          \"hidden_state_size\": 256,\n          \"core_arch\": \"mlp\",\n          \"fc_layer\": 2,\n          \"out_dim_fc_0\": 128,\n          \"out_dim_fc_1\": 64,\n          \"encode_layer\": \"16-32\"\n        },\n        \"algorithm\": \"mappo\",\n        \"space_obs\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595aa020000000000008c0f67796d2e7370616365732e64696374948c04446963749493942981947d94288c06737061636573948c0b636f6c6c656374696f6e73948c0b4f726465726564446963749493942952948c036f6273948c0e67796d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994681093948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c065f7368617065944b1285948c036c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289648000000000000000000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c29468128c02663494898887945294284b0368164e4e4e4affffffff4affffffff4b007494624b1285948c014394749452948c046869676894681d289648000000000000000000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8429468214b1285946824749452948c086c6f775f72657072948c062d3130302e30948c09686967685f72657072948c053130302e30948c0d626f756e6465645f62656c6f7794681d289612000000000000000101010101010101010101010101010101019468128c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b1285946824749452948c0d626f756e6465645f61626f766594681d289612000000000000000101010101010101010101010101010101019468344b1285946824749452948c0a5f6e705f72616e646f6d944e75627368184e68104e683f4e75622e\"\n        },\n        \"space_act\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005958c000000000000008c1367796d2e7370616365732e6469736372657465948c0844697363726574659493942981947d94288c016e944b058c057374617274944b008c065f736861706594298c056474797065948c056e756d707994680893948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        \"num_agents\": 3,\n        \"episode_limit\": 25,\n        \"policy_mapping_info\": {\n          \"simple_adversary\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_crypto\": {\n            \"description\": \"two team cooperate, one team attack\",\n            \"team_prefix\": [\n              \"eve_\",\n              \"bob_\",\n              \"alice_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_push\": {\n            \"description\": \"one team target on landmark, one team attack\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_tag\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_spread\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_reference\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_world_comm\": {\n            \"description\": \"two team cooperate and attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"leadadversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_speaker_listener\": {\n            \"description\": \"two team cooperate\",\n            \"team_prefix\": [\n              \"speaker_\",\n              \"listener_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          }\n        },\n        \"agent_name_ls\": [\n          \"agent_0\",\n          \"agent_1\",\n          \"agent_2\"\n        ]\n      }\n    },\n    \"seed\": 321,\n    \"env\": \"mpe_simple_spread\",\n    \"num_gpus_per_worker\": 0,\n    \"num_gpus\": 1,\n    \"num_workers\": 1,\n    \"multiagent\": {\n      \"policies\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059515000000000000008f94288c0d7368617265645f706f6c69637994902e\"\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c9020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b024b004b004b034b014b1b430488005300944e8594298c086167656e745f6964948c07657069736f6465948c066b77617267739487948c6b2f6d6e742f632f55736572732f67726179732f4f6e6544726976652f4465736b746f702f676974687562207468696e67732f436f6f70657261746976654265686176696f75722f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e7079948c083c6c616d6264613e944b7a4300948c127368617265645f706f6c6963795f6e616d6594859429749452947d94288c0b5f5f7061636b6167655f5f948c126d61726c6c69622e6d61726c2e616c676f73948c085f5f6e616d655f5f948c196d61726c6c69622e6d61726c2e616c676f732e72756e5f6363948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c9493942952948594749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1872756e5f63632e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493948c0d7368617265645f706f6c696379948594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      }\n    },\n    \"framework\": \"torch\",\n    \"evaluation_interval\": 50,\n    \"simple_optimizer\": false\n  },\n  \"local_dir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread\",\n  \"evaluated_params\": {\n    \"lr\": 0.001,\n    \"model/custom_model_config/model_arch_args/encode_layer\": \"16-32\"\n  },\n  \"experiment_tag\": \"3_lr=0.001,encode_layer=16-32\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b8000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d94286808473ff0000000000000680947000000000000000075658c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"episode_reward_mean\": 999999,\n    \"timesteps_total\": 1000000,\n    \"training_iteration\": 9999999\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1748287407.5407524,\n  \"logdir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00003_3_lr=0.001,encode_layer=16-32_2025-05-26_12-23-27\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00003_3_lr=0.001,encode_layer=16-32_2025-05-26_12-23-27/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trial_runner.py\\\", line 890, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\\\", line 788, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/worker.py\\\", line 1625, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::MAPPOTrainer.train()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=MAPPOTrainer)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 679, in train\\n    raise e\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 668, in train\\n    result = Trainable.train(self)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trainable.py\\\", line 283, in train\\n    result = self.step()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\\\", line 206, in step\\n    step_results = next(self.train_exec_impl)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 756, in __next__\\n    return next(self.built_iterator)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 876, in apply_flatten\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 471, in base_iterator\\n    yield ray.get(futures, timeout=timeout)\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::RolloutWorker.par_iter_next()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=<ray.rllib.evaluation.rollout_worker.modify_class.<locals>.Class object at 0x7f7efdc55d90>)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 1151, in par_iter_next\\n    return next(self.local_it)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 378, in gen_rollouts\\n    yield self.sample()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 753, in sample\\n    batches = [self.input_reader.next()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 103, in next\\n    batches = [self.get_data()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 233, in get_data\\n    item = next(self._env_runner)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 622, in _env_runner\\n    eval_results = _do_policy_eval(\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 1017, in _do_policy_eval\\n    summarize(to_eval)))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 20, in summarize\\n    return _printer.pformat(_summarize(obj))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in _summarize\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in <dictcomp>\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 32, in _summarize\\n    return [_summarize(x) for x in obj]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 32, in <listcomp>\\n    return [_summarize(x) for x in obj]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 29, in _summarize\\n    \\\"data\\\": _summarize(obj._asdict()),\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in _summarize\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 25, in <dictcomp>\\n    return {k: _summarize(v) for k, v in obj.items()}\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 39, in _summarize\\n    elif obj.dtype == np.object or obj.dtype.type is np.str_:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/numpy/__init__.py\\\", line 305, in __getattr__\\n    raise AttributeError(__former_attrs__[attr])\\nAttributeError: module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_to_cloud\": null,\n  \"checkpoint_freq\": 100,\n  \"checkpoint_at_end\": true,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}",
    "{\n  \"trainable_name\": \"MAPPOTrainer\",\n  \"trial_id\": \"e44ca_00002\",\n  \"config\": {\n    \"batch_mode\": \"truncate_episodes\",\n    \"train_batch_size\": 50,\n    \"sgd_minibatch_size\": 50,\n    \"lr\": 0.0005,\n    \"entropy_coeff\": 0.01,\n    \"num_sgd_iter\": 2,\n    \"clip_param\": 0.3,\n    \"use_gae\": true,\n    \"lambda\": 1.0,\n    \"vf_loss_coeff\": 1.0,\n    \"kl_coeff\": 0.2,\n    \"vf_clip_param\": 10.0,\n    \"model\": {\n      \"custom_model\": \"Centralized_Critic_Model\",\n      \"custom_model_config\": {\n        \"env\": \"mpe\",\n        \"env_args\": {\n          \"continuous_actions\": false,\n          \"max_cycles\": 25,\n          \"map_name\": \"simple_spread\"\n        },\n        \"mask_flag\": false,\n        \"global_state_flag\": false,\n        \"opp_action_in_cc\": true,\n        \"agent_level_batch_update\": false,\n        \"force_coop\": true,\n        \"local_mode\": true,\n        \"share_policy\": \"group\",\n        \"evaluation_interval\": 50,\n        \"framework\": \"torch\",\n        \"num_workers\": 1,\n        \"num_gpus\": 1,\n        \"num_cpus_per_worker\": 1,\n        \"num_gpus_per_worker\": 0,\n        \"checkpoint_freq\": 100,\n        \"checkpoint_end\": true,\n        \"restore_path\": {\n          \"model_path\": \"\",\n          \"params_path\": \"\"\n        },\n        \"stop_iters\": 9999999,\n        \"stop_timesteps\": 2000000,\n        \"stop_reward\": 999999,\n        \"seed\": 321,\n        \"local_dir\": \"\",\n        \"model_arch_args\": {\n          \"hidden_state_size\": 256,\n          \"core_arch\": \"mlp\",\n          \"fc_layer\": 2,\n          \"out_dim_fc_0\": 128,\n          \"out_dim_fc_1\": 64,\n          \"encode_layer\": \"16-32\"\n        },\n        \"algorithm\": \"mappo\",\n        \"space_obs\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"800595aa020000000000008c0f67796d2e7370616365732e64696374948c04446963749493942981947d94288c06737061636573948c0b636f6c6c656374696f6e73948c0b4f726465726564446963749493942952948c036f6273948c0e67796d2e7370616365732e626f78948c03426f789493942981947d94288c056474797065948c056e756d707994681093948c02663494898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c065f7368617065944b1285948c036c6f77948c126e756d70792e636f72652e6e756d65726963948c0b5f66726f6d627566666572949394289648000000000000000000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c20000c8c29468128c02663494898887945294284b0368164e4e4e4affffffff4affffffff4b007494624b1285948c014394749452948c046869676894681d289648000000000000000000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8420000c8429468214b1285946824749452948c086c6f775f72657072948c062d3130302e30948c09686967685f72657072948c053130302e30948c0d626f756e6465645f62656c6f7794681d289612000000000000000101010101010101010101010101010101019468128c02623194898887945294284b038c017c944e4e4e4affffffff4affffffff4b007494624b1285946824749452948c0d626f756e6465645f61626f766594681d289612000000000000000101010101010101010101010101010101019468344b1285946824749452948c0a5f6e705f72616e646f6d944e75627368184e68104e683f4e75622e\"\n        },\n        \"space_act\": {\n          \"_type\": \"CLOUDPICKLE_FALLBACK\",\n          \"value\": \"8005958c000000000000008c1367796d2e7370616365732e6469736372657465948c0844697363726574659493942981947d94288c016e944b058c057374617274944b008c065f736861706594298c056474797065948c056e756d707994680893948c02693894898887945294284b038c013c944e4e4e4affffffff4affffffff4b007494628c0a5f6e705f72616e646f6d944e75622e\"\n        },\n        \"num_agents\": 3,\n        \"episode_limit\": 25,\n        \"policy_mapping_info\": {\n          \"simple_adversary\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_crypto\": {\n            \"description\": \"two team cooperate, one team attack\",\n            \"team_prefix\": [\n              \"eve_\",\n              \"bob_\",\n              \"alice_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_push\": {\n            \"description\": \"one team target on landmark, one team attack\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_tag\": {\n            \"description\": \"one team attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_spread\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_reference\": {\n            \"description\": \"one team cooperate\",\n            \"team_prefix\": [\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_world_comm\": {\n            \"description\": \"two team cooperate and attack, one team survive\",\n            \"team_prefix\": [\n              \"adversary_\",\n              \"leadadversary_\",\n              \"agent_\"\n            ],\n            \"all_agents_one_policy\": false,\n            \"one_agent_one_policy\": true\n          },\n          \"simple_speaker_listener\": {\n            \"description\": \"two team cooperate\",\n            \"team_prefix\": [\n              \"speaker_\",\n              \"listener_\"\n            ],\n            \"all_agents_one_policy\": true,\n            \"one_agent_one_policy\": true\n          }\n        },\n        \"agent_name_ls\": [\n          \"agent_0\",\n          \"agent_1\",\n          \"agent_2\"\n        ]\n      }\n    },\n    \"seed\": 321,\n    \"env\": \"mpe_simple_spread\",\n    \"num_gpus_per_worker\": 0,\n    \"num_gpus\": 1,\n    \"num_workers\": 1,\n    \"multiagent\": {\n      \"policies\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"80059515000000000000008f94288c0d7368617265645f706f6c69637994902e\"\n      },\n      \"policy_mapping_fn\": {\n        \"_type\": \"CLOUDPICKLE_FALLBACK\",\n        \"value\": \"800595c9020000000000008c1b7261792e636c6f75647069636b6c652e636c6f75647069636b6c65948c0d5f6275696c74696e5f747970659493948c0a4c616d6264615479706594859452942868028c08436f6465547970659485945294284b024b004b004b034b014b1b430488005300944e8594298c086167656e745f6964948c07657069736f6465948c066b77617267739487948c6b2f6d6e742f632f55736572732f67726179732f4f6e6544726976652f4465736b746f702f676974687562207468696e67732f436f6f70657261746976654265686176696f75722f4d41524c6c69622f6d61726c6c69622f6d61726c2f616c676f732f72756e5f63632e7079948c083c6c616d6264613e944b7a4300948c127368617265645f706f6c6963795f6e616d6594859429749452947d94288c0b5f5f7061636b6167655f5f948c126d61726c6c69622e6d61726c2e616c676f73948c085f5f6e616d655f5f948c196d61726c6c69622e6d61726c2e616c676f732e72756e5f6363948c085f5f66696c655f5f94680f754e4e68008c105f6d616b655f656d7074795f63656c6c9493942952948594749452948c207261792e636c6f75647069636b6c652e636c6f75647069636b6c655f66617374948c125f66756e6374696f6e5f736574737461746594939468217d947d9428681968108c0c5f5f7175616c6e616d655f5f948c1872756e5f63632e3c6c6f63616c733e2e3c6c616d6264613e948c0f5f5f616e6e6f746174696f6e735f5f947d948c0e5f5f6b7764656661756c74735f5f944e8c0c5f5f64656661756c74735f5f944e8c0a5f5f6d6f64756c655f5f94681a8c075f5f646f635f5f944e8c0b5f5f636c6f737572655f5f9468008c0a5f6d616b655f63656c6c9493948c0d7368617265645f706f6c696379948594529485948c175f636c6f75647069636b6c655f7375626d6f64756c6573945d948c0b5f5f676c6f62616c735f5f947d947586948652302e\"\n      }\n    },\n    \"framework\": \"torch\",\n    \"evaluation_interval\": 50,\n    \"simple_optimizer\": false\n  },\n  \"local_dir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread\",\n  \"evaluated_params\": {\n    \"lr\": 0.0005,\n    \"model/custom_model_config/model_arch_args/encode_layer\": \"16-32\"\n  },\n  \"experiment_tag\": \"2_lr=0.0005,encode_layer=16-32\",\n  \"location\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"8005953a000000000000008c0e7261792e74756e652e747269616c948c084c6f636174696f6e9493942981947d94288c08686f73746e616d65944e8c03706964944e75622e\"\n  },\n  \"resources\": {\n    \"cpu\": 1,\n    \"gpu\": 0,\n    \"memory\": 0,\n    \"object_store_memory\": 0,\n    \"extra_cpu\": 0,\n    \"extra_gpu\": 0,\n    \"extra_memory\": 0,\n    \"extra_object_store_memory\": 0,\n    \"custom_resources\": {},\n    \"extra_custom_resources\": {}\n  },\n  \"placement_group_factory\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"800595b8000000000000008c1f7261792e74756e652e7574696c732e706c6163656d656e745f67726f757073948c15506c6163656d656e7447726f7570466163746f72799493942981947d94288c085f62756e646c6573945d94287d94288c0343505594473ff00000000000008c0347505594473ff0000000000000757d94286808473ff0000000000000680947000000000000000075658c095f7374726174656779948c045041434b948c055f6172677394298c075f6b7761726773947d9475622e\"\n  },\n  \"stopping_criterion\": {\n    \"episode_reward_mean\": 999999,\n    \"timesteps_total\": 1000000,\n    \"training_iteration\": 9999999\n  },\n  \"log_to_file\": [\n    null,\n    null\n  ],\n  \"max_failures\": 0,\n  \"_last_result\": {},\n  \"_default_result_or_future\": null,\n  \"last_update_time\": -Infinity,\n  \"metric_analysis\": {},\n  \"n_steps\": [\n    5,\n    10\n  ],\n  \"metric_n_steps\": {},\n  \"export_formats\": [],\n  \"status\": \"ERROR\",\n  \"start_time\": 1748287406.7383814,\n  \"logdir\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00002_2_lr=0.0005,encode_layer=16-32_2025-05-26_12-23-26\",\n  \"runner\": null,\n  \"last_debug\": 0,\n  \"error_file\": \"/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/MAPPOTrainer_mpe_simple_spread_e44ca_00002_2_lr=0.0005,encode_layer=16-32_2025-05-26_12-23-26/error.txt\",\n  \"error_msg\": \"Traceback (most recent call last):\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trial_runner.py\\\", line 890, in _process_trial\\n    results = self.trial_executor.fetch_result(trial)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/ray_trial_executor.py\\\", line 788, in fetch_result\\n    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\\\", line 105, in wrapper\\n    return func(*args, **kwargs)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/worker.py\\\", line 1625, in get\\n    raise value.as_instanceof_cause()\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::MAPPOTrainer.train()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=MAPPOTrainer)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 679, in train\\n    raise e\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer.py\\\", line 668, in train\\n    result = Trainable.train(self)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/tune/trainable.py\\\", line 283, in train\\n    result = self.step()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/agents/trainer_template.py\\\", line 206, in step\\n    step_results = next(self.train_exec_impl)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 756, in __next__\\n    return next(self.built_iterator)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 843, in apply_filter\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 876, in apply_flatten\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 783, in apply_foreach\\n    for item in it:\\n  [Previous line repeated 1 more time]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 471, in base_iterator\\n    yield ray.get(futures, timeout=timeout)\\nray.exceptions.RayTaskError(AttributeError): \\u001b[36mray::RolloutWorker.par_iter_next()\\u001b[39m (pid=31119, ip=172.19.89.72, repr=<ray.rllib.evaluation.rollout_worker.modify_class.<locals>.Class object at 0x7f7efd7f7e80>)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/util/iter.py\\\", line 1151, in par_iter_next\\n    return next(self.local_it)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 378, in gen_rollouts\\n    yield self.sample()\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\\\", line 753, in sample\\n    batches = [self.input_reader.next()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 103, in next\\n    batches = [self.get_data()]\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 233, in get_data\\n    item = next(self._env_runner)\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 599, in _env_runner\\n    _process_observations(\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/evaluation/sampler.py\\\", line 822, in _process_observations\\n    logger.info(\\\"Filtered obs: {}\\\".format(summarize(filtered_obs)))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 20, in summarize\\n    return _printer.pformat(_summarize(obj))\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/ray/rllib/utils/debug.py\\\", line 39, in _summarize\\n    elif obj.dtype == np.object or obj.dtype.type is np.str_:\\n  File \\\"/home/tristongrayston/anaconda3/envs/cooperative/lib/python3.8/site-packages/numpy/__init__.py\\\", line 305, in __getattr__\\n    raise AttributeError(__former_attrs__[attr])\\nAttributeError: module 'numpy' has no attribute 'object'.\\n`np.object` was a deprecated alias for the builtin `object`. To avoid this error in existing code, use `object` by itself. Doing this will not modify any behavior and is safe. \\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\\n\",\n  \"trial_name_creator\": null,\n  \"custom_trial_name\": null,\n  \"custom_dirname\": null,\n  \"saving_to\": null,\n  \"remote_checkpoint_dir_prefix\": null,\n  \"sync_to_cloud\": null,\n  \"checkpoint_freq\": 100,\n  \"checkpoint_at_end\": true,\n  \"keep_checkpoints_num\": null,\n  \"checkpoint_score_attr\": \"training_iteration\",\n  \"sync_on_checkpoint\": true,\n  \"checkpoint_manager\": {\n    \"_type\": \"CLOUDPICKLE_FALLBACK\",\n    \"value\": \"80059566010000000000008c1b7261792e74756e652e636865636b706f696e745f6d616e61676572948c11436865636b706f696e744d616e616765729493942981947d94288c146b6565705f636865636b706f696e74735f6e756d94477ff00000000000008c165f636865636b706f696e745f73636f72655f6465736394898c165f636865636b706f696e745f73636f72655f61747472948c12747261696e696e675f697465726174696f6e948c1c6e65776573745f70657273697374656e745f636865636b706f696e749468008c0a436865636b706f696e749493942981947d94288c0773746f72616765948c0a70657273697374656e74948c0576616c7565944e8c06726573756c74947d9475628c195f6e65776573745f6d656d6f72795f636865636b706f696e7494680b2981947d9428680e8c066d656d6f72799468104e68117d9475628c115f626573745f636865636b706f696e7473945d948c0b5f6d656d62657273686970948f9475622e\"\n  },\n  \"restore_path\": null,\n  \"restoring_from\": null,\n  \"num_failures\": 1,\n  \"has_new_resources\": false,\n  \"results\": \"80054e2e\",\n  \"best_result\": \"80054e2e\",\n  \"param_config\": \"80054e2e\",\n  \"extra_arg\": \"80054e2e\",\n  \"_state_json\": null,\n  \"_state_valid\": false\n}"
  ],
  "runner_data": {
    "_max_pending_trials": 17,
    "_metric": null,
    "_total_time": 0,
    "_iteration": 9,
    "_has_errored": true,
    "_fail_fast": false,
    "_server_port": null,
    "_cached_trial_decisions": {},
    "_queued_trial_decisions": {},
    "_updated_queue": true,
    "_result_wait_time": 1,
    "_should_stop_experiment": false,
    "_local_checkpoint_dir": "/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread",
    "_remote_checkpoint_dir": null,
    "_stopper": {
      "_type": "CLOUDPICKLE_FALLBACK",
      "value": "80059527000000000000008c107261792e74756e652e73746f70706572948c0b4e6f6f7053746f707065729493942981942e"
    },
    "_resumed": false,
    "_start_time": 1748287404.0328379,
    "_last_checkpoint_time": -Infinity,
    "_session_str": "2025-05-26_12-23-24",
    "checkpoint_file": "/mnt/c/Users/grays/OneDrive/Desktop/github things/CooperativeBehaviour/exp_results/mappo_mlp_simple_spread/experiment_state-2025-05-26_12-23-24.json",
    "_checkpoint_period": "auto",
    "launch_web_server": false
  },
  "stats": {
    "start_time": 1748287404.0328379,
    "timestamp": 1748287405.1847992
  }
}